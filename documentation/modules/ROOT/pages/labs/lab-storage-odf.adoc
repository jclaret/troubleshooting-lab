= Storage - OpenShift Data Foundation Troubleshooting
include::../_attributes.adoc[]

:imagesdir: assets/images

== Lab Overview

This comprehensive lab covers troubleshooting OpenShift Data Foundation (ODF) across multiple scenarios including Ceph cluster health issues, capacity management, file storage problems, block storage misconfigurations, and S3 object storage connectivity issues. You'll learn to diagnose and resolve storage problems in OpenShift environments.

=== Learning Objectives

By completing this lab, you will be able to:

* Understand ODF architecture and Ceph cluster components
* Use ODF debugging tools including Ceph toolbox and must-gather
* Diagnose and resolve Ceph cluster health and storage issues

=== Reference Documentation

* link:https://docs.redhat.com/en/documentation/red_hat_openshift_data_foundation/4.18/html/troubleshooting_openshift_data_foundation[Troubleshooting OpenShift Data Foundation]
* link:https://docs.ceph.com/en/quincy/rados/troubleshooting/[Ceph Troubleshooting Guide]

== OpenShift Data Foundation Architecture Overview

OpenShift Data Foundation provides software-defined storage using Ceph as the underlying storage system. Key components include:

* **Ceph Monitors (MONs)**: Maintain cluster maps and coordinate between components
* **Object Storage Daemons (OSDs)**: Store data and handle replication/recovery
* **Managers (MGRs)**: Track metrics and expose cluster information via REST API
* **Metadata Servers (MDSes)**: Store metadata for CephFS file system operations
* **RADOS Gateway (RGW)**: Provides S3-compatible object storage interface

=== Understanding Storage Types and Access Modes

ODF provides the following types of storage:

- Block storage: ODF uses Ceph’s RADOS Block Device (RBD) to create block storage volumes that can be used for high-performance and demanding workloads.
- File storage: ODF utilizes CephFS, a distributed file system built on top of Ceph, to provide scalable and shared file storage as an alternative to NFS.
- Object storage: ODF leverages Ceph’s RADOS Gateway (RGW) and NooBaa to provide object storage. This can be used to store and retrieve large amounts of unstructured data, such as media files and backups.

==== Access Modes

In the CLI, the access modes are abbreviated to:

RWO - ReadWriteOnce - the volume can be mounted as read-write by a single node. ReadWriteOnce access mode still can allow multiple pods to access (read from or write to) that volume when the pods are running on the same node
ROX - ReadOnlyMany - the volume can be mounted as read-only by many nodes.
RWX - ReadWriteMany - the volume can be mounted as read-write by many nodes.
RWOP - ReadWriteOncePod - the volume can be mounted as read-write by a single Pod

== ODF Troubleshooting Commands

When troubleshooting OpenShift Data Foundation issues, use these commands to investigate and resolve problems:

[.lines_space]
[.console-input]
[source,bash, subs="+macros,+attributes"]
----

# Get the OpenShift Data Foundation operator version and channel
oc get csv -n openshift-storage
oc get subs -n openshift-storage
oc get installplan -n openshift-storage

# Check ODF cluster status
oc get storagecluster -n openshift-storage
oc get cephcluster -n openshift-storage

# View all ODF pods and their status
oc get pods -n openshift-storage -o wide

# Enable Rook-Ceph Toolbox
oc patch storagecluster ocs-storagecluster -n openshift-storage --type json --patch '[{ "op": "replace", "path": "/spec/enableCephTools", "value": true }]'

# Check Ceph cluster health using toolbox
oc -n openshift-storage rsh deployment/rook-ceph-tools ceph status
oc -n openshift-storage rsh deployment/rook-ceph-tools ceph health detail

# Check OSD tree and status
oc -n openshift-storage rsh deployment/rook-ceph-tools ceph osd tree
oc -n openshift-storage rsh deployment/rook-ceph-tools ceph osd stat

# View cluster capacity and usage
oc -n openshift-storage rsh deployment/rook-ceph-tools ceph df

# Check Ceph monitor status
oc -n openshift-storage rsh deployment/rook-ceph-tools ceph mon stat
oc -n openshift-storage rsh deployment/rook-ceph-tools ceph mon dump

# Check CephFS status
oc -n openshift-storage rsh deployment/rook-ceph-tools ceph fs status
oc -n openshift-storage rsh deployment/rook-ceph-tools ceph mds stat

# Check RGW status
oc -n openshift-storage rsh deployment/rook-ceph-tools ceph rgw stat

# Check storageclasses
oc get storageclass | grep openshift-storage

# Check node labels for ODF storage nodes
oc get nodes -l cluster.ocs.openshift.io/openshift-storage

# Check for events
oc get events -n openshift-storage --sort-by='.lastTimestamp'

# ODF Operator logs
oc logs -n openshift-storage deployment/ocs-operator --tail=50
oc logs -n openshift-storage deployment/rook-ceph-operator --tail=50
oc logs -n openshift-storage deployment/noobaa-operator --tail=50

# Logs for plugin pods like cephfs or rbd to detect any problem in the PVC mount of the app-pod
oc logs csi-cephfsplugin-<ID> -n openshift-storage -c csi-cephfsplugin
oc logs csi-rbdplugin-<ID> -n openshift-storage -c csi-rbdplugin

# Logs for all the containers in the CSI pod
oc logs csi-cephfsplugin-<ID> -n openshift-storage --all-containers
oc logs csi-rbdplugin-<ID> -n openshift-storage --all-containers

# Logs for cephfs or rbd provisioner pods to detect problems if PVC is not in BOUND state
oc logs csi-cephfsplugin-provisioner-<ID> -n openshift-storage -c csi-cephfsplugin
oc logs csi-rbdplugin-provisioner-<ID> -n openshift-storage -c csi-rbdplugin

# To generate logs for all the containers in the CSI pod:
oc logs csi-cephfsplugin-provisioner-<ID> -n openshift-storage --all-containers
oc logs csi-rbdplugin-provisioner-<ID> -n openshift-storage --all-containers

# Generating OpenShift Data Foundation logs using cluster-info command
oc cluster-info dump -n openshift-storage --output-directory=<directory-name>

# When using Local Storage Operator, generating logs can be done using cluster-info command:
oc cluster-info dump -n openshift-local-storage --output-directory=<directory-name>
----

== Collecting Diagnostic Information with Must-Gather 

Use the must-gather tool to collect log files and diagnostic information so that you or Red Hat support can review the problem and determine a solution.

Run the must-gather command from the client connected to the OpenShift Data Foundation cluster:

[.lines_space]
[.console-input]
[source,bash, subs="+macros,+attributes"]
----
oc adm must-gather --image=registry.redhat.io/odf4/odf-must-gather-rhel9:v4.18 --dest-dir=<directory-name>
----

*<directory-name>* is the name of the directory where you want to write the data to.

This collects the following information in the specified directory:

- All Red Hat OpenShift Data Foundation cluster related Custom Resources (CRs) with their namespaces.
- Pod logs of all the Red Hat OpenShift Data Foundation related pods.
- Output of some standard Ceph commands like Status, Cluster health, and others.

To specify a relative time period for logs gathered, such as within 5 hours or 2 days

[.lines_space]
[.console-input]
[source,bash, subs="+macros,+attributes"]
----
# within 5 hours
oc adm must-gather --image=$(oc -n openshift-storage get deployment.apps/ocs-operator -o jsonpath='{.spec.template.metadata.annotations.operators\.openshift\.io/must-gather-image}') --dest-dir=_<directory-name>_ /usr/bin/gather since=5h

# rfc3339-timestamp - example 2020-11-10T04:00:00+00:00
oc adm must-gather --image=$(oc -n openshift-storage get deployment.apps/ocs-operator -o jsonpath='{.spec.template.metadata.annotations.operators\.openshift\.io/must-gather-image}') --dest-dir=_<directory-name>_ /usr/bin/gather since-time=2020-11-10T04:00:00+00:00 (starting from 4 am UTC on 11 Nov 2020)
----

=== Running must-gather in modular mode 

OpenShift Data Foundation must-gather can take a long time to run in some environments. To avoid this, run must-gather in modular mode and collect only the resources you require using the following command:

[.lines_space]
[.console-input]
[source,bash, subs="+macros,+attributes"]
----
# ODF logs (includes Ceph resources, namespaced resources, clusterscoped resources and Ceph logs)
oc adm must-gather --image=registry.redhat.io/odf4/odf-must-gather-rhel9:v4.18 -- /usr/bin/gather --odf

# Noobaa logs
oc adm must-gather --image=registry.redhat.io/odf4/odf-must-gather-rhel9:v4.18 -- /usr/bin/gather --noobaa

# Ceph commands and pod logs
oc adm must-gather --image=registry.redhat.io/odf4/odf-must-gather-rhel9:v4.18 -- /usr/bin/gather --ceph

# Ceph daemon, kernel, journal logs, and crash reports
oc adm must-gather --image=registry.redhat.io/odf4/odf-must-gather-rhel9:v4.18 -- /usr/bin/gather --ceph-logs
----

== Troubleshooting ODF Health and Alerts

OpenShift Data Foundation continuously monitors cluster health and can automatically resolve many common issues. However, some problems require manual intervention and troubleshooting.

**Where to Check for Issues:**

The OpenShift Web Console provides several locations to monitor ODF health:

* **Observe → Alerting → Firing**: Shows active alerts that need attention (Filter by Alerting and User)
* **Home → Overview → Cluster → Storage**: Displays overall cluster health status
* **Storage → Data Foundation → Storage System**: Detailed storage system information
* **Storage → Data Foundation → Storage System → Overview**: Block, File, and Object storage status

**Understanding Health Checks:**

ODF uses a comprehensive set of health checks to monitor cluster status. Each health check has a unique identifier and provides specific information about potential issues. These checks help administrators quickly identify and resolve storage problems before they impact applications. 

=== Common ODF Issues and Troubleshooting Approaches

**Reference Documentation:**
For a complete list of health alerts and their resolutions, see the link:https://docs.redhat.com/en/documentation/red_hat_openshift_data_foundation/4.18/html-single/troubleshooting_openshift_data_foundation/index#resolving-cluster-alerts_rhodf[ODF Troubleshooting Guide].

**See below some examples::**

=== CephClusterWarningState
**What it means:** This alert reflects that the storage cluster has been in a warning state for an unacceptable amount of time. While the storage operations will continue to function in this state, it is recommended to fix the errors so that the cluster does not get into an error state. Check for other alerts that might have triggered prior to this one and troubleshoot those alerts first.

**Impact:** High 

**Troubleshooting Steps when:**

- pod status: pending

[.lines_space]
[.console-input]
[source,bash, subs="+macros,+attributes"]
----
# Check for resource issues, pending Persistent Volume Claims (PVCs), node assignment, and kubelet problems
oc project openshift-storage
oc get pod | grep {ceph-component}

# Set MYPOD as the variable for the pod that is identified as the problem pod
MYPOD=<pod_name>
oc get pod/${MYPOD} -o wide
----

- pod status: NOT pending, running, but NOT ready

[.lines_space]
[.console-input]
[source,bash, subs="+macros,+attributes"]
----
# Check the readiness probe
oc describe pod/${MYPOD}
----

- pod status: NOT pending, but NOT running

[.lines_space]
[.console-input]
[source,bash, subs="+macros,+attributes"]
----
# Check for application or image issues:
oc logs pod/${MYPOD}
----

Run the following command to gather the debugging information for the Ceph cluster

[.lines_space]
[.console-input]
[source,bash, subs="+macros,+attributes"]
----
oc adm must-gather --image=registry.redhat.io/odf4/odf-must-gather-rhel9:v4.18
----

=== CephOSDDiskNotResponding
**What it means:** A disk device is not responding. Check whether all the Object Storage Devices (OSDs) are up and running.

**Impact:** Medium 

**Troubleshooting Steps when:**

- pod status: pending

[.lines_space]
[.console-input]
[source,bash, subs="+macros,+attributes"]
----
# Check for resource issues, pending Persistent Volume Claims (PVCs), node assignment, and kubelet problems
oc project openshift-storage
oc get pod | grep rook-ceph

# Set MYPOD as the variable for the pod that is identified as the problem pod
MYPOD=<pod_name>
oc get pod/${MYPOD} -o wide
----

- pod status: NOT pending, running, but NOT ready

[.lines_space]
[.console-input]
[source,bash, subs="+macros,+attributes"]
----
# Check the readiness probe
oc describe pod/${MYPOD}
----

- pod status: NOT pending, but NOT running

[.lines_space]
[.console-input]
[source,bash, subs="+macros,+attributes"]
----
# Check for application or image issues:
oc logs pod/${MYPOD}
----

Run the following command to gather the debugging information for the Ceph cluster

[.lines_space]
[.console-input]
[source,bash, subs="+macros,+attributes"]
----
oc adm must-gather --image=registry.redhat.io/odf4/odf-must-gather-rhel9:v4.18
----

=== PersistentVolumeUsageCritical
**What it means:** A Persistent Volume Claim has exceeded 85% of its capacity, risking data loss.

**Impact:** High - Potential data loss if not addressed.

**Resolution:**

Expand the PVC size to increase the capacity.

- Log in to the OpenShift Web Console.
- Click Storage → PersistentVolumeClaim.
- Select openshift-storage from the Project drop-down list.
- On the PVC you want to expand, click Action menu (⋮) → Expand PVC.
- Update the Total size to the desired size.
- Click Expand.
- Alternatively, you can delete unnecessary data that may be taking up space.


== Exercise 1: ODF CLI Installation and Health Check

This exercise will guide you through installing the ODF CLI tool and performing a basic health check on your ODF cluster. This is a straightforward installation and verification exercise.

=== Objective

Install the ODF CLI tool and use it to verify the health status of your OpenShift Data Foundation cluster.

=== Step 1: Install ODF CLI

[.lines_space]
[.console-input]
[source,bash, subs="+macros,+attributes"]
----
# Navigate to the ODF files directory
cd /home/demo-user/troubleshooting-lab/lab-materials/04-storage-odf/files

# Extract the ODF CLI tool
tar xzvf odf-cli-4.18.5-linux-amd64.tar.gz

# Install ODF CLI to system PATH
sudo mv odf-amd64 /usr/local/bin/odf

# Verify installation
odf -h
----

**Expected Result:** You should see the ODF CLI help menu with available commands.

=== Step 2: Perform Health Check

[.lines_space]
[.console-input]
[source,bash, subs="+macros,+attributes"]
----
# Run comprehensive health check
odf get health
----

**Expected Result:** The health check should show:
- All ODF components in healthy state
- No error messages
- Proper resource counts

=== Step 3: Verify ODF Components

[.lines_space]
[.console-input]
[source,bash, subs="+macros,+attributes"]
----
odf get health
Info: Checking if at least three mon pods are running on different nodes
rook-ceph-mon-a-f9d9db54f-kmxkz	Running	openshift-storage	ip-10-0-58-83.ec2.internal
rook-ceph-mon-b-7d8655f8c-cf899	Running	openshift-storage	ip-10-0-22-253.ec2.internal
rook-ceph-mon-c-56f58b44b7-d9dw8	Running	openshift-storage	ip-10-0-31-119.ec2.internal

Info: Checking mon quorum and ceph health details
Info: HEALTH_OK

Info: Checking if at least three osd pods are running on different nodes
rook-ceph-osd-0-58bb7bf6b5-9mwtk	Running	openshift-storage	ip-10-0-58-83.ec2.internal
rook-ceph-osd-1-bbbf4bb9b-hxg5c	Running	openshift-storage	ip-10-0-22-253.ec2.internal
rook-ceph-osd-2-6649755888-l5xgb	Running	openshift-storage	ip-10-0-31-119.ec2.internal

Info: Pods that are in 'Running' or `Succeeded` status
ceph-csi-controller-manager-5b7f76c6c5-kwcvf 	 Running 	 openshift-storage	 ip-10-0-34-69.ec2.internal
csi-addons-controller-manager-657588b8b-sgcjz 	 Running 	 openshift-storage	 ip-10-0-34-69.ec2.internal
csi-cephfsplugin-5qqll 	 Running 	 openshift-storage	 ip-10-0-58-83.ec2.internal
csi-cephfsplugin-bb8n6 	 Running 	 openshift-storage	 ip-10-0-34-69.ec2.internal
csi-cephfsplugin-frtqq 	 Running 	 openshift-storage	 ip-10-0-22-253.ec2.internal
csi-cephfsplugin-hmxb6 	 Running 	 openshift-storage	 ip-10-0-31-119.ec2.internal
csi-cephfsplugin-provisioner-69b55f8cfb-242js 	 Running 	 openshift-storage	 ip-10-0-34-69.ec2.internal
csi-cephfsplugin-provisioner-69b55f8cfb-g8fxm 	 Running 	 openshift-storage	 ip-10-0-22-253.ec2.internal
csi-cephfsplugin-s8zrp 	 Running 	 openshift-storage	 ip-10-0-38-52.ec2.internal
csi-rbdplugin-26fcx 	 Running 	 openshift-storage	 ip-10-0-31-119.ec2.internal
csi-rbdplugin-k6jfd 	 Running 	 openshift-storage	 ip-10-0-34-69.ec2.internal
csi-rbdplugin-provisioner-5c94c7675-46bzw 	 Running 	 openshift-storage	 ip-10-0-22-253.ec2.internal
csi-rbdplugin-provisioner-5c94c7675-hbw7m 	 Running 	 openshift-storage	 ip-10-0-31-119.ec2.internal
csi-rbdplugin-swrbs 	 Running 	 openshift-storage	 ip-10-0-38-52.ec2.internal
csi-rbdplugin-vmdtw 	 Running 	 openshift-storage	 ip-10-0-22-253.ec2.internal
csi-rbdplugin-zj8lz 	 Running 	 openshift-storage	 ip-10-0-58-83.ec2.internal
noobaa-core-0 	 Running 	 openshift-storage	 ip-10-0-34-69.ec2.internal
noobaa-db-pg-0 	 Running 	 openshift-storage	 ip-10-0-34-69.ec2.internal
noobaa-endpoint-7577dfb6bf-jckfb 	 Running 	 openshift-storage	 ip-10-0-34-69.ec2.internal
noobaa-operator-56b464bcdc-hvdjh 	 Running 	 openshift-storage	 ip-10-0-34-69.ec2.internal
ocs-metrics-exporter-67d6c74f9d-jrkdm 	 Running 	 openshift-storage	 ip-10-0-34-69.ec2.internal
ocs-operator-69b97c4cfc-s9j82 	 Running 	 openshift-storage	 ip-10-0-31-119.ec2.internal
odf-console-f99f69bcd-f527s 	 Running 	 openshift-storage	 ip-10-0-31-119.ec2.internal
odf-operator-controller-manager-65f45d55b7-hdpv5 	 Running 	 openshift-storage	 ip-10-0-34-69.ec2.internal
rook-ceph-crashcollector-ip-10-0-22-253.ec2.internal-6bf6cm4rvv 	 Running 	 openshift-storage	 ip-10-0-22-253.ec2.internal
rook-ceph-crashcollector-ip-10-0-31-119.ec2.internal-5d766w7m2m 	 Running 	 openshift-storage	 ip-10-0-31-119.ec2.internal
rook-ceph-crashcollector-ip-10-0-58-83.ec2.internal-69d7bcphvxc 	 Running 	 openshift-storage	 ip-10-0-58-83.ec2.internal
rook-ceph-exporter-ip-10-0-22-253.ec2.internal-74688884dc-n9kzl 	 Running 	 openshift-storage	 ip-10-0-22-253.ec2.internal
rook-ceph-exporter-ip-10-0-31-119.ec2.internal-6bcb566c5b-825qv 	 Running 	 openshift-storage	 ip-10-0-31-119.ec2.internal
rook-ceph-exporter-ip-10-0-58-83.ec2.internal-7cf8847b47-4drjj 	 Running 	 openshift-storage	 ip-10-0-58-83.ec2.internal
rook-ceph-mds-ocs-storagecluster-cephfilesystem-a-67d7865bbtb7r 	 Running 	 openshift-storage	 ip-10-0-31-119.ec2.internal
rook-ceph-mds-ocs-storagecluster-cephfilesystem-b-564bb78cf4j5d 	 Running 	 openshift-storage	 ip-10-0-58-83.ec2.internal
rook-ceph-mgr-a-76979d4dc8-7wczd 	 Running 	 openshift-storage	 ip-10-0-22-253.ec2.internal
rook-ceph-mgr-b-55f6b5b447-ld8ft 	 Running 	 openshift-storage	 ip-10-0-58-83.ec2.internal
rook-ceph-mon-a-f9d9db54f-kmxkz 	 Running 	 openshift-storage	 ip-10-0-58-83.ec2.internal
rook-ceph-mon-b-7d8655f8c-cf899 	 Running 	 openshift-storage	 ip-10-0-22-253.ec2.internal
rook-ceph-mon-c-56f58b44b7-d9dw8 	 Running 	 openshift-storage	 ip-10-0-31-119.ec2.internal
rook-ceph-operator-859bd4447d-f7m85 	 Running 	 openshift-storage	 ip-10-0-22-253.ec2.internal
rook-ceph-osd-0-58bb7bf6b5-9mwtk 	 Running 	 openshift-storage	 ip-10-0-58-83.ec2.internal
rook-ceph-osd-1-bbbf4bb9b-hxg5c 	 Running 	 openshift-storage	 ip-10-0-22-253.ec2.internal
rook-ceph-osd-2-6649755888-l5xgb 	 Running 	 openshift-storage	 ip-10-0-31-119.ec2.internal
rook-ceph-osd-prepare-ocs-deviceset-0-data-0ng65v-7qwc9 	 Succeeded 	 openshift-storage	 ip-10-0-22-253.ec2.internal
rook-ceph-osd-prepare-ocs-deviceset-1-data-0d2gf6-8xkwd 	 Succeeded 	 openshift-storage	 ip-10-0-58-83.ec2.internal
rook-ceph-osd-prepare-ocs-deviceset-2-data-0vg9c4-9gk8q 	 Succeeded 	 openshift-storage	 ip-10-0-31-119.ec2.internal
rook-ceph-tools-695fddf56d-rgrf4 	 Running 	 openshift-storage	 ip-10-0-58-83.ec2.internal
ux-backend-server-6d4d8fbd94-x5mgm 	 Running 	 openshift-storage	 ip-10-0-34-69.ec2.internal

Warning: Pods that are 'Not' in 'Running' status

Info: Checking placement group status
Info: 	PgState: active+clean, PgCount: 144

Info: Checking if at least one mgr pod is running
rook-ceph-mgr-a-76979d4dc8-7wczd	Running	openshift-storage	ip-10-0-22-253.ec2.internal
rook-ceph-mgr-b-55f6b5b447-ld8ft	Running	openshift-storage	ip-10-0-58-83.ec2.internal
----

**Expected Result:** All components should show healthy status with no errors.

== Exercise 2: Troubleshooting ODF misconfiguration

=== Scenario Setup

In this exercise, you will execute a script that modifies the current ODF deployment configuration. This script will intentionally introduce configuration changes that will cause the ODF cluster to enter a `HEALTH_WARNING` state, simulating a real-world troubleshooting scenario.

Navigate to the ODF troubleshooting lab and deploy the exercise scenario:

[.lines_space]
[.console-input]
[source,bash, subs="+macros,+attributes"]
----
# Change to the ODF troubleshooting lab directory
cd /home/demo-user/troubleshooting-lab/lab-materials/04-storage-odf/00-odf-miss

# Execute the ODF configuration script
chmod +x odf-config.sh
./odf-config.sh

# Monitor ODF cluster status
oc get storagecluster -n openshift-storage -w
----

=== Investigation Challenge

**YOUR MISSION**: Investigate the ODF cluster behavior and identify any issues.

**What to check:**

- What is the status of the ODF storage cluster?
- Are there any alerts or warnings in the ODF console?
- Which nodes are labeled for ODF storage?
- Are there any OSD pods failing or in error state?
- What does the Ceph cluster health show?

Use the troubleshooting commands provided earlier to investigate the cluster behavior systematically.

.Click to reveal the solution
[%collapsible]
====
**Solution Implementation:**

Execute the fix script to restore ODF node labeling:

[.lines_space]
[.console-input]
[source,bash, subs="+macros,+attributes"]
----
# Execute the fix script
./solution/odf-fix.sh
----
====

=== Verification

Monitor the ODF recovery process:

[.lines_space]
[.console-input]
[source,bash, subs="+macros,+attributes"]
----
# Watch ODF storage cluster status during recovery
oc get storagecluster -n openshift-storage
oc get cephcluster -n openshift-storage

# Monitor OSD pod restart
oc get pods -n openshift-storage -w

# Check when all OSD pods are running
oc get pods -n openshift-storage | grep osd

# Verify Ceph cluster health after recovery
oc -n openshift-storage rsh deployment/rook-ceph-tools ceph status

# Verify node labels are restored
oc get nodes -l cluster.ocs.openshift.io/openshift-storage
----

== Exercise 3: Troubleshooting ODF Health Issues

== Scenario Setup

Run the following script to **activate the scenario**. It will **intentionally modify cluster state** to simulate a real incident.

Navigate to the ODF troubleshooting lab and deploy the exercise scenario:

[.lines_space]
[.console-input]
[source,bash, subs="+macros,+attributes"]
----
# Change to the ODF troubleshooting lab directory
cd /home/demo-user/troubleshooting-lab/lab-materials/04-storage-odf/00-odf-health

# Execute the ODF configuration script
chmod +x odf-issue.sh
./odf-issue.sh

# Monitor ODF cluster status
oc get storagecluster -n openshift-storage
oc get cephcluster -n openshift-storage
odf get health

# Operator logs (recent tail)
oc logs -n openshift-storage -l name=ocs-operator --tail=100
oc logs -n openshift-storage -l app=rook-ceph-operator --tail=100
oc logs -n openshift-storage -l name=odf-operator --tail=100
----

After activation, wait 3-5 minutes, then begin.

=== Investigation Challenge

**YOUR MISSION**: Investigate the ODF cluster behavior and identify any issues.

**What to check:**

- What is the status of the ODF storage cluster?
- Are there any alerts or warnings in the ODF console?
- Are there any OSD pods failing or in error state?
- What does the Ceph cluster health show?

Use the troubleshooting commands provided above to investigate the cluster step by step. You will also need to access the AWS Console (see AWS Console Access Setup) to complete the investigation.

.Click to reveal the solution
[%collapsible]
====
**Solution Implementation:**

Execute the fix script to restore ODF node labeling:

[.lines_space]
[.console-input]
[source,bash, subs="+macros,+attributes"]
----
# Find the NotReady node from scenario activation
oc get nodes
----

Restore the instance in AWS Console:

- Open **AWS Console** → **Compute** → **EC2** → **Instances**.  
- Select the instance that is in **Stopped** state.  
- Click **Instance state** → **Start instance**.  
- Confirm the action. The instance should transition to **Running**.

====

=== Verification

Monitor the ODF recovery process:

[.lines_space]
[.console-input]
[source,bash, subs="+macros,+attributes"]
----
# Watch ODF storage cluster status during recovery
oc get storagecluster -n openshift-storage
oc get cephcluster -n openshift-storage

# Check all pods are running
oc get pods -n openshift-storage

# Verify node labels are restored
oc get nodes 
----

== Exercise 4: File Storage Troubleshooting

=== Scenario Setup

You'll deploy an application into the `odf-file` namespace. This application is designed to upload and store photos using ODF file storage. The application is expected to function with 3 pods in Running state, but something is not working correctly.

**What gets deployed:**
- The namespace `odf-file`
- A Deployment that runs a photo upload application with 3 replicas
- A Service and Route (so you can reach the app via web interface)
- A PersistentVolumeClaim for storing uploaded photos

**Expected behavior:** Once all pods are in Running state, you should be able to upload **all** the files found in the directory `/home/demo-user/troubleshooting-lab/Photos` through the web interface. If you encounter any errors during the upload process, check the pod logs to understand what's happening.

Navigate to the ODF troubleshooting lab and deploy the exercise scenario:

[.lines_space]
[.console-input]
[source,bash, subs="+macros,+attributes"]
----
# Change to the second lab directory
cd /home/demo-user/troubleshooting-lab/lab-materials/04-storage-odf/02-odf-file
----

=== Deploying the Application

Deploy the application and its configuration:

[.lines_space]
[.console-input]
[source,bash, subs="+macros,+attributes"]
----
# Deploy the exercise scenario
oc apply -k .

# Monitor application deployment
oc get pods -n odf-file
oc get pvc -n odf-file

# Verify PVC binding and size
oc get pvc -n odf-file
oc describe pvc upload-data -n odf-file

# Check storage class
oc describe storageclass ocs-storagecluster-cephfs

# Test application functionality
oc get route image-uploader -n odf-file -o jsonpath='{.spec.host}'
----

=== Investigation Challenge

**YOUR MISSION**: Investigate the file storage issues and identify the root causes preventing the application from working properly.

**What to check:**

- How many pods are actually running and why?
- What is the current size of the PVC?
- What is the current AccessModes of the PVC?
- What happens when you try to upload files through the web interface?
- What type of storage is being used and can it be expanded?
- Can you change the AccessMode of an existing PVC?
- How could you resolve both the size and access mode issues?

**Investigation Steps:**

1. **Check pod status**: Are all 3 pods running or are some stuck in ContainerCreating/Pending?
2. **Examine PVC configuration**: Look at the current size and access modes
3. **Test file upload**: Try uploading a photo through the web interface
4. **Check pod logs**: Look for specific error messages when uploads fail
5. **Investigate storage class**: Understand what type of storage is being used

.Click to reveal the solution
[%collapsible]
====
**Solution Implementation: Recreating PVC with Correct Configuration**

Execute the fix script to recreate the PVC with proper size and access mode:

[.lines_space]
[.console-input]
[source,bash, subs="+macros,+attributes"]
----
# Execute the fix script
chmod +x solution/fix-pvc.sh
./solution/fix-pvc.sh
----

**During the initial deployment, you will encounter 2 problems:**

- **AccessMode Issue**: This will cause errors and leave pods in ContainerCreating or Pending state

   ```
   Warning  FailedAttachVolume  2m51s  attachdetach-controller  Multi-Attach error for volume "pvc-d1f6cf6e-ee78-44a8-92fd-49f361113b73" Volume is already used by pod(s) image-uploader-745bb8fb7b-cb872, image-uploader-745bb8fb7b-ftmp4
   ```

- **PVC Size Issue**: This will prevent file uploads with errors like:

   ```
   OSError: [Errno 122] Disk quota exceeded
   ```

**Expected Behavior After Fix:**
After resolving both issues, the application should successfully upload all photos from the `/home/demo-user/troubleshooting-lab/Photos` directory through the web interface, with all 3 pods running and sharing the same storage volume.

=== Verification

Verify that the kernel parameter is correctly applied:

[.lines_space]
[.console-input]
[source,bash, subs="+macros,+attributes"]
----
# Verify application now starts successfully
oc get pods -n odf-file
oc get pvc -n odf-file

# Test application functionality and upload all photos
oc get route image-uploader -n odf-file -o jsonpath='{.spec.host}'
----

====


== Lab Summary

This comprehensive ODF troubleshooting lab covered critical storage scenarios:

* **Storage Health**: Diagnosed and resolved node labeling issues affecting cluster performance
* **File Storage**: Resolved capacity issues through PVC expansion and storage type investigation
* **Block Storage**: Fixed multi-attach problems by understanding access modes and replica scaling
* **Object Storage**: Debugged authentication and configuration mismatches in bucket provisioning

== Additional Resources

* link:https://docs.redhat.com/en/documentation/red_hat_openshift_data_foundation/4.18[OpenShift Data Foundation Documentation]
* link:https://docs.redhat.com/en/documentation/red_hat_openshift_data_foundation/4.18/html-single/troubleshooting_openshift_data_foundation/index#troubleshooting-alerts-and-errors-in-openshift-data-foundation[Troubleshooting alerts and errors in OpenShift Data Foundation]
* link:https://access.redhat.com/documentation/en-us/red_hat_openshift_data_foundation/4.18/html/troubleshooting_openshift_data_foundation[ODF Troubleshooting Guide]
* link:https://access.redhat.com/solutions/4502501[Red Hat Solutions for ODF Issues]
* link:https://access.redhat.com/downloads/content/547/ver=4/rhel---9/4.17.0/x86_64/product-software[Download odf-cli tool]
* link https://kubernetes.io/docs/concepts/storage/persistent-volumes/#access-modes[AccessModes]
* link https://access.redhat.com/articles/5001441[Supported configurations for Red Hat OpenShift Data Foundation 4.X]
