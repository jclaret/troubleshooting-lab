= OpenShift Resources and Tools
include::../_attributes.adoc[]

== Lab Overview

This foundational lab introduces essential Red Hat tools and methodologies for OpenShift cluster health validation and diagnostic data collection. You'll learn to establish baseline triage workflows using official Red Hat tooling and documentation, preparing you for both proactive monitoring and reactive troubleshooting scenarios.

=== Learning Objectives

By completing this lab, you will be able to:

* Validate OpenShift cluster health using standard Red Hat diagnostic commands
* Create comprehensive must-gather collections for support cases and offline analysis
* Generate node-level sosreports for deep system troubleshooting
* Apply Red Hat's recommended triage workflow for systematic problem resolution
* Prepare standardized diagnostic artifacts for Red Hat Support cases

== Exercise 1: Establishing Baseline Cluster Health

=== Understanding Cluster Health Indicators

Before troubleshooting any specific issue, establishing a comprehensive baseline of your cluster's health is essential. Red Hat provides standardized commands and tools designed specifically for this purpose.

=== Initial Cluster Assessment

Execute the following commands to gather baseline cluster information:

[.lines_space]
[.console-input]
[source,bash, subs="+macros,+attributes"]
----
# Verify your authentication and cluster access
oc whoami

# Check OpenShift version and update status
oc version
oc get clusterversion

# Examine cluster operator status (critical for overall health)
oc get co

# Validate node readiness and detailed information
oc get nodes -o wide

# Validate machine config pool status
oc get machineconfigpool

# Review all pods across namespaces for system-wide health
oc get pods -A

# Check cluster-wide events and alerts
oc get events -A --sort-by=.lastTimestamp | head -20
oc get events -A --field-selector type=Warning --sort-by=.lastTimestamp

# Assess resource utilization at node and pod levels
oc adm top nodes
oc adm top pods -A
oc adm top pods -A --containers=true

----

=== Interpreting Health Indicators

After executing the baseline commands, analyze the output to identify potential concerns:

* *ClusterOperators Status*: All operators should show `Available=True`, `Progressing=False`, `Degraded=False`
* *Node Status*: All nodes should display `Ready` status with appropriate roles
* *Pod Health*: System pods should be `Running` or `Completed`, not `Pending`, `CrashLoopBackOff`, or `Error`
* *Resource Utilization*: CPU and memory usage should be within acceptable thresholds
* *Recent Events*: No critical errors or warnings in recent cluster events

=== Using Red Hat Resources

When issues are identified, leverage official Red Hat resources to guide your troubleshooting approach:

* *Product Documentation*: Reference official https://docs.redhat.com/en/documentation/openshift_container_platform/[OpenShift documentation] for configuration guidance
* *Red Hat Knowledgebase*: Search for known issues and problem signaturesi in https://access.redhat.com/[Customer Portal] 
* *Cluster Monitoring*: Use built-in Prometheus/Alertmanager for operator status and alerts on OpenShift Console > Observe > Dashboard
* *Support Case Preparation*: Gather diagnostic artifacts if Red Hat Support engagement is needed in https://access.redhat.com/support/cases/[Customer Support]

== Exercise 2: Creating Comprehensive Must-Gather Collections

=== Diagnostic Steps: Understanding Must-Gather Purpose

Must-gather is Red Hat's standardized diagnostic collection tool that packages cluster information in a format optimized for both Red Hat Support analysis and offline troubleshooting. Different types of must-gather collections serve specific diagnostic purposes.

=== Information Gathering: Generic Cluster Data Collection

Create a comprehensive baseline must-gather collection:

[.lines_space]
[.console-input]
[source,bash, subs="+macros,+attributes"]
----
# Create organized directory structure for diagnostic data
mkdir logs && cd logs

# Generate standard must-gather with timestamp
oc adm must-gather --dest-dir=./must-gather-$(date +%F)

# Verify collection creation and size
ll
drwxr-xr-x. 3 demo-user users 4096 Aug  5 10:46 must-gather-2025-08-05
----

=== Component-Specific Collections

For targeted troubleshooting, create component-specific must-gather collections using specialized images:

[.lines_space]
[.console-input]
[source,bash, subs="+macros,+attributes"]
----
# OpenShift Data Foundation specific collection
oc adm must-gather \
  --image-stream=openshift/must-gather \
  --image=registry.redhat.io/odf4/odf-must-gather-rhel9:v4.18

# Verify multiple collections
ll
total 12
drwxr-xr-x. 3 demo-user users 4096 Aug  5 10:46 must-gather-2025-08-05
drwxr-xr-x. 4 demo-user users 4096 Aug  5 11:04 must-gather.local.8832762126482069764
----

[NOTE]
====
Substitute component-specific images for targeted data collection

Reference: link:https://docs.redhat.com/en/documentation/openshift_container_platform/4.19/html/support/gathering-cluster-data#gathering-data-specific-features_gathering-cluster-data[Gathering data about specific features]
====

=== Advanced Must-Gather Options

Utilize enhanced filtering options for efficient data collection:

[.lines_space]
[.console-input]
[source,bash, subs="+macros,+attributes"]
----
# Collect data from last 24 hours only
oc adm must-gather --since=24h

# Alternative time-based collection with specific timestamp
oc adm must-gather --since-time=$(date -d '-24 hours' +%Y-%m-%dT%T.%9N%:z)
----

== Exercise 3: Audit Log Collection and Analysis

=== Understanding Audit Log Importance

OpenShift audit logs provide detailed records of API server requests, essential for security analysis, compliance reporting, and troubleshooting authentication/authorization issues.

=== Comprehensive Audit Data Collection

Collect audit logs using specialized must-gather commands:

[.lines_space]
[.console-input]
[source,bash, subs="+macros,+attributes"]
----
# Dedicated audit log collection
oc adm must-gather -- /usr/bin/gather_audit_logs

# Combined standard and audit log collection
oc adm must-gather -- '/usr/bin/gather && /usr/bin/gather_audit_logs'
----

=== Advanced Audit Log Filtering

Apply sophisticated filtering to audit logs for targeted analysis:

[.lines_space]
[.console-input]
[source,bash, subs="+macros,+attributes"]
----
# Filter OAuth API server logs excluding 'get' operations
oc adm node-logs ip-10-0-39-122.ec2.internal \
  --path=oauth-apiserver/audit.log \
  | jq 'select(.verb != "get")'

# Analyze OpenShift API server audit logs by user
oc adm node-logs ip-10-0-39-122.ec2.internal \
  --path=oauth-apiserver/audit.log \
  | jq 'select(.user.username == "myusername")'
----

[TIP]
====
For comprehensive audit log filtering examples, reference: link:https://docs.redhat.com/en/documentation/openshift_container_platform/4.19/html/security_and_compliance/audit-log-view#security-audit-log-basic-filtering_audit-log-view[Filtering audit logs documentation]
====

== Exercise 4: Node-Level Diagnostic Collection with SosReport

=== Understanding SosReport Capabilities

SosReport provides deep operating system-level diagnostics from individual cluster nodes, essential for troubleshooting issues that span the container and host OS boundary.

=== Generating Node-Level Diagnostics

Execute sosreport collection on a target node:

[.lines_space]
[.console-input]
[source,bash, subs="+macros,+attributes"]
----
# Identify available nodes for diagnostic collection
oc get nodes

# Expected output showing node inventory
NAME                          STATUS   ROLES                  AGE   VERSION
ip-10-0-39-122.ec2.internal   Ready    control-plane,master   27h   v1.31.10
ip-10-0-40-228.ec2.internal   Ready    control-plane,master   27h   v1.31.10
ip-10-0-54-169.ec2.internal   Ready    control-plane,master   27h   v1.31.10
ip-10-0-41-193.ec2.internal   Ready    worker                 27h   v1.31.10
ip-10-0-50-174.ec2.internal   Ready    worker                 27h   v1.31.10
ip-10-0-51-124.ec2.internal   Ready    worker                 27h   v1.31.10
ip-10-0-58-191.ec2.internal   Ready    worker                 27h   v1.31.10
----

=== SosReport Generation Process

Execute sosreport collection using oc debug node access:

[.lines_space]
[.console-input]
[source,bash, subs="+macros,+attributes"]
----
# Access target node using debug pod
oc debug node/ip-10-0-39-122.ec2.internal

# Within the debug session, execute the following sequence:
sh-5.1# chroot /host
sh-5.1# toolbox  
sh-5.1# sos report --all-logs
sh-5.1# exit
----

[NOTE]
====
During execution, sosreport will prompt you with several interactive questions (case number, contact information, etc.). You can press Enter to accept defaults or provide any values - the answers don't affect the data collection process.
====

After completion, the command will display output similar to:
[.lines_space]
[.console-output]
[source,text]
----
Your sos report has been generated and saved in:
	/host/var/tmp/sosreport-ip-10-0-39-122-2025-09-01-pbfjqgd.tar.xz
----

[TIP]
====
Gathering data about your cluster, reference: link:https://docs.redhat.com/en/documentation/openshift_container_platform/4.19/html/support/gathering-cluster-data#about-sosreport_gathering-cluster-data[About sosreport]
====

=== Retrieving SosReport Archive

Extract the generated sosreport from the node to your workstation using the exact filename from the previous step:

[.lines_space]
[.console-input]
[source,bash, subs="+macros,+attributes"]
----
# Copy sosreport archive from node to local system
oc debug node/ip-10-0-39-122.ec2.internal -- bash -c \
  'cat /host/var/tmp/sosreport-ip-10-0-39-122-SupportCase123456-2025-08-05-fenkgpz.tar.xz' \
  > sosreport-ip-10-0-39-122-SupportCase123456-2025-08-05-fenkgpz.tar.xz

# Verify successful transfer and file size
ll sosreport*
-rw-r--r--. 1 demo-user users 30536992 Aug  5 13:01 sosreport-ip-10-0-39-122-SupportCase123456-2025-08-05-fenkgpz.tar.xz
----

=== Preparation for Support Cases

When engaging Red Hat Support, provide:

* Recent must-gather collection (generic and component-specific if applicable)
* Relevant sosreports from affected nodes
* Clear problem description with timeline of events
* Steps already taken and their outcomes as well as the reproducer

== Exercise 5: Analyzing SosReport Data with XSOS

=== Understanding XSOS (SosReport Examiner)

The `xsos` tool is a powerful utility for analyzing sosreport archives offline. It provides instant system summaries by parsing and formatting data from dozens of files and commands within a sosreport, making it easy to quickly understand system state, resource utilization, and potential issues without manually navigating through hundreds of files.

=== Installing XSOS

Install the `xsos` tool on your local system using multiple methods:

[.lines_space]
[.console-input]
[source,bash, subs="+macros,+attributes"]
----
# Download and install to /usr/local/bin
curl -sL https://raw.githubusercontent.com/ryran/xsos/master/xsos | sudo tee /usr/local/bin/xsos > /dev/null && sudo chmod +x /usr/local/bin/xsos

# Verify installation
xsos -h
----

=== Basic SosReport Analysis

Extract and analyze a sosreport using `xsos`:

[.lines_space]
[.console-input]
[source,bash, subs="+macros,+attributes"]
----
# Extract the sosreport archive
tar -xf sosreport-ip-10-0-39-122-SupportCase123456-2025-08-05-fenkgpz.tar.xz

# Navigate to the extracted directory
cd sosreport-ip-10-0-39-122-SupportCase123456-2025-08-05-fenkgpz

# Full system analysis with all modules
xsos -a

# System overview with memory and CPU details
xsos -omc

# Check CPU, PCI devices, and network interfaces
xsos -cln .

# Analyze network interfaces and configuration
xsos -e .

# Check disk usage and filesystem information
xsos -d .

# Review process information
xsos --ps

# Kernel crash dump configuration
xsos --kdump

# System kernel parameters
xsos --sysctl
----

[NOTE]
====
XSOS is particularly useful for:

* **Quick System Overview**: Instant understanding of system state and resources
* **Offline Analysis**: Analyze sosreports without requiring system access

Reference: https://github.com/ryran/xsos[XSOS GitHub Repository]
====

== Exercise 6: Analyzing Must-Gather Data with OMC

=== Understanding OMC (OpenShift Must-Gather Client)

The `omc` tool is a powerful utility that allows you to inspect and analyze must-gather data using familiar `oc` command syntax. This tool is particularly valuable for offline analysis, support case preparation, and post-incident investigation when you need to examine cluster state from a specific point in time.

=== Installing OMC

Install the `omc` tool on your local system:

[.lines_space]
[.console-input]
[source,bash, subs="+macros,+attributes"]
----
# Download and install omc for Linux to /usr/local/bin
curl -sL https://github.com/gmeghnag/omc/releases/latest/download/omc_$(uname)_$(uname -m).tar.gz | tar xzf - omc && sudo mv omc /usr/local/bin/ && chmod +x /usr/local/bin/omc

# Verify installation
omc -h
----

=== Using OMC with Must-Gather Data

Point `omc` to your must-gather directory and use it like the `oc` command:

[.lines_space]
[.console-input]
[source,bash, subs="+macros,+attributes"]
----
# Point omc to a must-gather directory
omc use ./must-gather-2025-08-05/

# Now use omc commands just like oc
omc get clusterversion
omc get nodes -o wide
omc get pods -A
----

=== Advanced OMC Examples

Explore cluster state using advanced `omc` capabilities:

[.lines_space]
[.console-input]
[source,bash, subs="+macros,+attributes"]
----
# Check etcd cluster status with detailed information
omc etcd status

# Retrieve master nodes by label
omc get node -l node-role.kubernetes.io/master= -o name

# Check Prometheus alerts in firing or pending state
omc prom rules -s firing,pending -o wide

# Inspect certificates from configmaps and secrets
omc certs inspect

# View HAProxy backends from ingress controller config
omc haproxy backends
----

=== OMC for Support Case Analysis

Use `omc` to prepare comprehensive analysis for support cases:

[.lines_space]
[.console-input]
[source,bash, subs="+macros,+attributes"]
----
# Analyze cluster operators at the time of must-gather
omc get co -o wide

# Check node conditions and events
omc describe nodes ip-10-0-19-14.ec2.internal

# Examine pod status across all namespaces
omc get pods -A | egrep -v "Completed|Running"

# Review recent events leading up to the issue
omc get events -A --sort-by=.lastTimestamp | tail -50
----

[NOTE]
====
OMC is particularly useful for:

* **Offline Analysis**: Examine cluster state without requiring cluster access
* **Historical Investigation**: Analyze cluster state from specific time periods
* **Support Case Preparation**: Generate comprehensive reports for Red Hat Support
* **Post-Incident Review**: Understand cluster state during incidents

Reference: https://github.com/gmeghnag/omc[OMC GitHub Repository]
====

== Lab Summary

This foundational lab established essential skills for OpenShift cluster health validation and diagnostic data collection. You've learned to:

* Execute standardized Red Hat cluster health validation commands
* Create comprehensive must-gather collections for different troubleshooting scenarios
* Generate and extract node-level sosreports for deep system analysis
* Analyze must-gather data using the `omc` tool for offline investigation
* Analyze sosreport data using the `xsos` tool for comprehensive system analysis
* Apply Red Hat's systematic approach to diagnostic data collection

== Additional Resources

* link:https://docs.redhat.com/en/documentation/openshift_container_platform/4.19/html/support/gathering-cluster-data[Gathering data about your cluster]
* link:https://docs.redhat.com/en/documentation/openshift_container_platform/4.19/html/support/gathering-cluster-data#about-sosreport_gathering-cluster-data[SosReport Documentation]
* link:https://github.com/gmeghnag/omc[OMC - OpenShift Must-Gather Client]
* link:https://github.com/ryran/xsos[XSOS - SosReport Examiner]
* link:https://docs.redhat.com/en/documentation/openshift_container_platform/4.19/html-single/support/index#support-overview-troubleshooting-issues[Troubleshooting issues]
